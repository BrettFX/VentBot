Though it wasn't due till next classist
ohhhh, yo can you send me the numbers that you used for simulated annealing
all good man.
any, thanks man
You down to meet up with me and Jessie tomorrow. We are going to be in IT tomorrow all day. I am going to try and get their by 10:30, but Jessie will probably get their earlier.
Ok, no
No problem.
Lol
We are on the third floor of ITE
Yo, for question one what was your information gain for the split at humidity. I am getting a negative number.
That is weird. I got -.063. I must have accidentally added .1 somewhere
Awesome thanks, did you get      .884 for the first one.
Ya, the fuck. Ok, I am probably doing something really wrong lol.
So, for example when I was doing the info gain on outlook I was doing the entropy of the outlook - the weighted sum of the entropy of the class(play/not play) for each type of outlook.
Also, if you do it the entropy for the overcast outlook should be zero.
I got an entropy of .971 for the other 2.
Ya, then weighting them by multiplying them by 5/24
5/14
To weight them.
Then add them together. And subtract that value from 1.578
You have to
Ohhhhhh, ya you need to do that.
Ya, I talked to him after class about it to confirm and he said you have to weight it.
Ya, the formula wasn't even on the hand out
So hyped, just got the trained tree to work for the project. Took a lot of work, but it is finally done. Just need to get the search to work
Ya, it look like 7-8 hours. Once you figure it out it will all just click.
Did you ever see if homework 3 got posted for 436.
I have been looking for it and can't find it.
Ya, their is supposed to be one. Paul emailed her. We will find out.
Did you get the homework for 471 done yet?
I think I got it but I am not sure.
I set the weight for 0 to 0 and the weight for 1 to 1 and the threshold is 0
So if 1 is greater than or equal to zero it is true, but if 0 is less then 0 it is false. It has to be one since 0 always has to be zero.
I think I am write.
Right.
Awesome thanks man.
You then find the best information gain for the data with each specific output. So say if you split it at sunny you find the best information gain for the data that has an outlook of sunny and then split at that data and keep going. Like a Tree. So if you split at sunny and then the best information gain for the sunny data is the humidity data you then split the sunny data at humidity.
But raining data can be split at a different column because is it windy has a better information gain for rainy data then humidity.
Lol, I think I was just really tired last night. Just went through the problem and realized that it was way easier then I originally thought. Just set the weights and the threshold to 1. Since both inputs being 1 outputs 2 it is the only value greater than 1 that can be produced in the perceptron.
ya, totally. I just think I chose the simplest one lolz
Ya, same place as last time
I might be down. Reviewing for a coding challenge for CARFAX right now though. What did you want to go over, because I am a little bit confused on all this stuff as well
do you have the 436 book?
I feel like I am so fucked for this exam.
Ok, thanks man. I am just slowly trying to wrap my head around this Material. You done to meet for the exam and do a short review before.
Probably 1 or 2 I am going to get up at like 6:30 on Tuesday get a large coffee and just study my ass off. You can come by whenever I will let you know where I am. I am really going to have to be taught a lot of shit lol.
Awesome thanks
clutch. So, I am definitely going to be getting up at 6:30ish tomorrow. I am really screwed and am not sure what to study for this test. I will most likely be in the same place I normally am.
Ya, but I understood the stuff really well last time so it was a lot easier. These topics are way harder to conceptualize. lol
Oh, good looks. I haven’t even had a chance to look at that lol
Oh, is this exam cumulative?
ok, sounds good. I will be here
just trying to memorize as much as I can lol
how much about convolutional neural networks do we need to know for the test. I feel like he isn’t going to give a lot because of how confused people were during that lecture
Awesome thank, I have no clue if he is going to give us a lot from that section. He might lol
hell ya, if I had an easier time understanding it I would have no problem memorizing it. I am starting to understand how it works, but I feel like if I had to code it up that would be the best way to learn it or if their was a really good video showing how each process works
I could probably easily code a really simple one where only like 20 hidden layer nodes for each picture.
ya
Where are you? I am in the hall outside. Hard af
the not sure if I did get them right, but I was just guessing hard on the bayes net problem
Dude the one with the shifting centroid I had no clue about.
Was the PCA one the one with the different C-constant?
One you draw a hyper plane splitting the data and the other you ignore the outliers.
Ya, that is what I was assuming. I just looked at the data and realized that their where 2 outliers so that kinda gave it away for me.
exactly
